{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Query_Search.ipynb","provenance":[],"authorship_tag":"ABX9TyM/nDZUBtSfMUhtSjH1czfn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","address = \"MIRNews1401\"\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(address))\n","%cd /content/drive/My\\ Drive/$address"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PAkwKo4duodp","executionInfo":{"status":"ok","timestamp":1658910044643,"user_tz":-270,"elapsed":4635,"user":{"displayName":"Mohammad Hossein Shahmoradi","userId":"15934369456047471568"}},"outputId":"1a3ea529-36f0-4b7c-f408-73883c6560d2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/.shortcut-targets-by-id/1uNRlfx2_FJDSXd8hfzc-wkVrmSePMe3-/MIRNews1401\n"]}]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iom7K3XQtwbl","executionInfo":{"status":"ok","timestamp":1658911873600,"user_tz":-270,"elapsed":8588,"user":{"displayName":"Mohammad Hossein Shahmoradi","userId":"15934369456047471568"}},"outputId":"157890fa-c9b3-4a46-b264-e89440dea3a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: hazm in /usr/local/lib/python3.7/dist-packages (0.7.0)\n","Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from hazm) (0.2.1)\n","Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.7/dist-packages (from hazm) (3.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.7.3)\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.20.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.6)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.96)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.8.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.12.0+cu113)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.13.0+cu113)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.1.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.7.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.12.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence_transformers) (3.8.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.6.15)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n"]}],"source":["# Required installations\n","# -------------------------------------------\n","!pip install hazm\n","!pip install sentence_transformers\n","# -------------------------------------------"]},{"cell_type":"code","source":["# Required imports\n","# -------------------------------------------\n","import json\n","import math\n","from tqdm import tqdm\n","from hazm import *\n","import numpy as np\n","import pandas as pd\n","from collections import Counter\n","import numexpr as ne\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from scipy import sparse\n","from gensim.models.fasttext import FastText\n","from sentence_transformers import util, SentenceTransformer\n","# -------------------------------------------"],"metadata":{"id":"cShvoA3Nt5d-","executionInfo":{"status":"ok","timestamp":1658912020884,"user_tz":-270,"elapsed":779,"user":{"displayName":"Mohammad Hossein Shahmoradi","userId":"15934369456047471568"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["# Required Variable Initializations (Loads, Downloads, ...)\n","# -------------------------------------------\n","stop_words = stopwords_list()\n","normalizer = Normalizer()\n","lemmatizer = Lemmatizer()\n","news_details = np.load(\"./data/news_details.npy\", allow_pickle=True)\n","frequency_matrix = np.load(\"./data/boolean_frequency_matrix.npy\")\n","unique_token_list = np.load(\"./data/boolean_unique_token_list.npy\")\n","boolean_matrix = frequency_matrix.copy()\n","boolean_matrix[boolean_matrix > 0] = 1\n","transformer_model = SentenceTransformer('m3hrdadfi/bert-fa-base-uncased-wikinli-mean-tokens')\n","transformer_doc_embeddings = np.load(\"./data/transformer_doc_embeddings.npy\")\n","tfidf_vectorizer = TfidfVectorizer(smooth_idf=False, norm=\"l2\")\n","tfidf_vocabulary = json.load(open('./data/tfidf_vocabulary.json', mode = 'r'))\n","tfidf_idf = np.load(\"./data/tfidf_idf.npy\")\n","tfidf_vectorizer.idf_ = tfidf_idf\n","tfidf_vectorizer.vocabulary_ = tfidf_vocabulary\n","tfidf_embeddings = sparse.load_npz(\"./data/tfidf_embeddings.npz\")\n","ft_model = FastText.load(\"./data/fasttext.model\")\n","features = tfidf_vectorizer.get_feature_names_out()\n","idfs = tfidf_vectorizer.idf_\n","embedding_size = 100\n","fast_weighted_embeddings = np.load(\"./data/fast_weighted_embeddings.npy\")\n","frequency_matrix_df = pd.DataFrame(data = frequency_matrix, \n","                                   index = unique_token_list, \n","                                   columns = list(range(frequency_matrix.shape[1])))\n","boolean_matrix_df = pd.DataFrame(data = boolean_matrix, \n","                                 index = unique_token_list, \n","                                 columns = list(range(frequency_matrix.shape[1])))\n","# -------------------------------------------"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DliIppjYudP4","executionInfo":{"status":"ok","timestamp":1658912047638,"user_tz":-270,"elapsed":23211,"user":{"displayName":"Mohammad Hossein Shahmoradi","userId":"15934369456047471568"}},"outputId":"006b2835-8a58-42e3-cb22-fcce0188d8c6"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/m3hrdadfi_bert-fa-base-uncased-wikinli-mean-tokens. Creating a new one with MEAN pooling.\n"]}]},{"cell_type":"code","source":["# Required Functions (Variables in the previous block must be initialized first)\n","# -------------------------------------------\n","def preprocess_text(document):\n","        document = normalizer.normalize(document)\n","        \n","        tokens = word_tokenize(document)\n","        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n","        tokens = [word for word in tokens if word not in stop_words]\n","        tokens = [word for word in tokens if len(word) > 2]\n","\n","        preprocessed_text = ' '.join(tokens)\n","\n","        return preprocessed_text\n","\n","\n","\n","def boolean_retrieval(boolean_matrix_df, frequency_matrix_df, k, query_string, not_raw_tokens=[]):\n","\n","    # get all query tokens\n","    query_raw_tokens = word_tokenize(query_string)\n","\n","    # remove stop words\n","    query_tokens = [lemmatizer.lemmatize(token) for token in query_raw_tokens if token not in stop_words]\n","\n","    # remove stop words from not_tokens\n","    not_tokens = [lemmatizer.lemmatize(token) for token in not_raw_tokens if token not in stop_words]\n","\n","    # get all unique tokens which are already in our readmes \n","    unique_tokens = boolean_matrix_df.index.values.tolist()\n","\n","    # available tokens in query\n","    available_query_tokens = [token for token in query_tokens if token in unique_tokens]\n","\n","    # only choose specific rows of df which correspond to query tokens\n","    summary_df = boolean_matrix_df.loc[available_query_tokens]\n","    summary_frequency_df = frequency_matrix_df.loc[available_query_tokens]\n","\n","    # available tokens in not_tokens\n","    available_not_tokens = [token for token in not_tokens if token in unique_tokens]\n","\n","    # df consisting of only available_not_tokens\n","    summary_not_df = boolean_matrix_df.loc[available_not_tokens]\n","    arr = summary_not_df.values\n","    summary_not_df = pd.DataFrame(ne.evaluate('1 - arr'), columns=summary_not_df.columns, index=summary_not_df.index)\n","    summary_not_frequency_df = frequency_matrix_df.loc[available_not_tokens]\n","    arr = summary_not_frequency_df.values\n","    summary_not_frequency_df = pd.DataFrame(ne.evaluate('0 - arr'), columns=summary_not_frequency_df.columns, index=summary_not_df.index)\n","\n","    # specify boolean rating\n","    rating_1 = summary_df.sum().tolist()\n","    rating_2 = summary_not_df.sum().tolist()\n","    boolean_rating = [x + y for x, y in zip(rating_1, rating_2)]\n","\n","    # specify frequency rating\n","    rating_1 = summary_frequency_df.sum().tolist()\n","    rating_2 = summary_not_frequency_df.sum().tolist()\n","    frequency_rating = [x + y for x, y in zip(rating_1, rating_2)]\n","\n","    # sort indices based on ratings\n","    raw_indices = list(range(len(boolean_matrix_df.columns)))\n","    list_of_tuples = [(bool_item, freq_item) for bool_item, freq_item in zip(boolean_rating, frequency_rating)]\n","    zipped = zip(list_of_tuples, raw_indices)\n","    sorted_indices = [item for _, item in sorted(zipped, key=lambda pair: pair[0], reverse=True)]\n","    \n","    return sorted_indices[:k]\n","\n","\n","def query_expansion_embedding(query_emb, rel_list, non_rel_list):\n","    a = 1\n","    b = 0.8\n","    c = 0.1\n","    resault = a * query_emb + b * np.sum(rel_list)/len(rel_list) - c * np.sum(non_rel_list)/len(non_rel_list)\n","    return resault\n","\n","def boolean_search(text, K):\n","    my_indices = boolean_retrieval(boolean_matrix_df, frequency_matrix_df, K, text)\n","    return my_indices\n","\n","def transformer_search(text, K, expansion=False):\n","    query = preprocess_text(text)\n","    transformer_query_embedding = transformer_model.encode(query)\n","    transformer_list_sim = util.cos_sim(transformer_query_embedding, transformer_doc_embeddings)\n","    if expansion:\n","        sorted_list_sim = np.argsort(np.array(transformer_list_sim[0]))\n","        most_similar_emb = [transformer_doc_embeddings[i] for i in sorted_list_sim[::-1][:10]]\n","        least_similar_emb = [transformer_doc_embeddings[i] for i in sorted_list_sim[:][:10]]\n","        expanded = query_expansion_embedding(transformer_query_embedding, most_similar_emb, least_similar_emb)\n","        transformer_list_sim = util.cos_sim(expanded, transformer_doc_embeddings)\n","    \n","    transformer_most_similar_doc_indices = np.argsort(np.array(transformer_list_sim[0]))[::-1][:K]\n","    return transformer_most_similar_doc_indices\n","\n","def tfidf_search(text, K, expansion=False):\n","    query = [preprocess_text(text)]\n","    tfidf_query_vec = tfidf_vectorizer.transform(query)\n","    tfidf_similarities = cosine_similarity(tfidf_embeddings, tfidf_query_vec).flatten()\n","    if expansion:\n","        sorted_sim = np.argsort(tfidf_similarities, axis=0)\n","        most_similar_emb = [tfidf_embeddings[i] for i in sorted_sim[:-11:-1]]\n","        least_similar_emb = [tfidf_embeddings[i] for i in sorted_sim[:10]]\n","        expanded = query_expansion_embedding(tfidf_query_vec, most_similar_emb, least_similar_emb)\n","        tfidf_similarities = cosine_similarity(tfidf_embeddings, expanded).flatten()\n","\n","    tfidf_most_similar_doc_indices = np.argsort(tfidf_similarities, axis=0)[:-K-1:-1]\n","    return tfidf_most_similar_doc_indices\n","\n","def query_expansion_embedding(query_emb, rel_list, non_rel_list):\n","    a = 1\n","    b = 0.8\n","    c = 0.1\n","    resault = a * query_emb + b * np.sum(rel_list)/len(rel_list) - c * np.sum(non_rel_list)/len(non_rel_list)\n","    return resault\n","\n","def boolean_search(text, K):\n","    my_indices = boolean_retrieval(boolean_matrix_df, frequency_matrix_df, K, text)\n","    return my_indices\n","\n","def transformer_search(text, K, expansion=False):\n","    query = preprocess_text(text)\n","    transformer_query_embedding = transformer_model.encode(query)\n","    transformer_list_sim = util.cos_sim(transformer_query_embedding, transformer_doc_embeddings)\n","    if expansion:\n","        sorted_list_sim = np.argsort(np.array(transformer_list_sim[0]))\n","        most_similar_emb = [transformer_doc_embeddings[i] for i in sorted_list_sim[::-1][:10]]\n","        least_similar_emb = [transformer_doc_embeddings[i] for i in sorted_list_sim[:][:10]]\n","        expanded = query_expansion_embedding(transformer_query_embedding, most_similar_emb, least_similar_emb)\n","        transformer_list_sim = util.cos_sim(expanded, transformer_doc_embeddings)\n","    \n","    transformer_most_similar_doc_indices = np.argsort(np.array(transformer_list_sim[0]))[::-1][:K]\n","    return transformer_most_similar_doc_indices\n","\n","def tfidf_search(text, K, expansion=False):\n","    query = [preprocess_text(text)]\n","    tfidf_query_vec = tfidf_vectorizer.transform(query)\n","    tfidf_similarities = cosine_similarity(tfidf_embeddings, tfidf_query_vec).flatten()\n","    if expansion:\n","        sorted_sim = np.argsort(tfidf_similarities, axis=0)\n","        most_similar_emb = [tfidf_embeddings[i] for i in sorted_sim[:-11:-1]]\n","        least_similar_emb = [tfidf_embeddings[i] for i in sorted_sim[:10]]\n","        expanded = query_expansion_embedding(tfidf_query_vec, most_similar_emb, least_similar_emb)\n","        tfidf_similarities = cosine_similarity(tfidf_embeddings, expanded).flatten()\n","\n","    tfidf_most_similar_doc_indices = np.argsort(tfidf_similarities, axis=0)[:-K-1:-1]\n","    return tfidf_most_similar_doc_indices\n","\n","def ft_weighted_search(text, K, expansion):\n","    changed_text = preprocess_text(text)\n","    init_emb = np.zeros(embedding_size)\n","    for word in word_tokenize(changed_text):\n","        try:\n","            emb = ft_model.wv[word]\n","            resault = np.where(features == word)[0]\n","            if resault.size > 0:\n","                init_emb += idfs[resault[0]] * emb / np.linalg.norm(emb)\n","        except:\n","            pass\n","    ft_similarities = cosine_similarity(fast_weighted_embeddings, init_emb.reshape(1, -1)).flatten()\n","    if expansion:\n","        sorted_sim = np.argsort(ft_similarities, axis=0)\n","        most_similar_emb = [fast_weighted_embeddings[i] for i in sorted_sim[:-11:-1]]\n","        least_similar_emb = [fast_weighted_embeddings[i] for i in sorted_sim[:10]]\n","        expanded = query_expansion_embedding(init_emb, most_similar_emb, least_similar_emb)\n","        ft_similarities = cosine_similarity(fast_weighted_embeddings, expanded.reshape(1, -1)).flatten()\n","\n","    ft_most_similar_doc_indices = np.argsort(ft_similarities, axis=0)[:-K-1:-1]\n","    return ft_most_similar_doc_indices\n","\n","\n","def query_search(query_text, output_num, search_type, expansion=False):\n","    result_indices = []\n","    if search_type == 'boolean':\n","        if expansion:\n","            pass\n","        result_indices = boolean_search(query_text, output_num)\n","    elif search_type == 'transformer':\n","        result_indices = transformer_search(query_text, output_num, expansion)\n","    elif search_type == 'tfidf':\n","        result_indices = tfidf_search(query_text, output_num, expansion)\n","    elif search_type == 'fasttext':\n","        result_indices = ft_weighted_search(query_text, output_num, expansion)\n","    \n","    result = [news_details[i] for i in result_indices]\n","    return result\n","# -------------------------------------------"],"metadata":{"id":"yi_godFWueXU","executionInfo":{"status":"ok","timestamp":1658912056885,"user_tz":-270,"elapsed":752,"user":{"displayName":"Mohammad Hossein Shahmoradi","userId":"15934369456047471568"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["# Examples\n","# -------------------------------------------\n","query = 'تیم فوتبال پرسپولیس'\n","print([i['url'] for i in query_search(query, 10, 'fasttext', True)])\n","print([i['url'] for i in query_search(query, 10, 'fasttext', False)])\n","print([i['title'] for i in query_search(query, 10, 'fasttext', False)])\n","# -------------------------------------------"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LvuZs9hBzZd7","executionInfo":{"status":"ok","timestamp":1658912064243,"user_tz":-270,"elapsed":840,"user":{"displayName":"Mohammad Hossein Shahmoradi","userId":"15934369456047471568"}},"outputId":"39fca2cf-4c22-45ec-c8cd-acf88af8d5d8"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["['https://www.yjc.news/fa/news/8177512/تاریخ-مسابقات-لیگ-برتر-و-اردوی-تیم-ملی-فوتبال-اعلام-شد', 'https://www.yjc.news/fa/news/8162628/سمیعی-باشگاه-پانتولیکوس-یونان-از-استقلال-شکایت-کرده-است#comments', 'https://www.yjc.news/fa/news/8170441/رکورد-شکنی-فرزانه-فصیحی-در-ماده-۱۰۰-متر-بانوان', 'https://www.yjc.news/fa/news/8177591/نمایندگان-اسکیت-ایران-در-مسابقات-کاپ-آزاد-ایتالیا-طلایی-شدند', 'https://www.yjc.news/fa/news/8172584/لیگ-ملت\\u200cهای-والیبال-۲۰۲۲-ایتالیا-میزبان-مرحله-پایانی-شد', 'http://www.yjc.news/fa/news/8175327/صلاح-در-لیورپول-ماندنی-شد&via=yjcagency', 'https://www.yjc.news/fa/news/8171357/نتایج-دوندگان-کشورمان-در-مسابقات-دو-و-میدانی-جام-کازانوف', 'https://www.yjc.news/fa/news/8172660/برگزاری-فینال-لیگ-دسته-یک-کشتی-همزمان-با-تولد-آقا-تختی', 'https://www.yjc.news/fa/news/8188227/شکسته-شدن-۳-رکورد-ملی-در-رقابت\\u200cهای-دو-و-میدانی-قهرمانی-باشگاه\\u200cهای-کشور', 'https://www.yjc.news/fa/news/8172592/اعزام-اسنوکرباز\\u200cهای-جوان-ایران-به-مسابقات-جهانی']\n","['https://www.yjc.news/fa/news/8185765/ابراهیمی-از-پرسپولیس-جدا-شد', 'https://www.yjc.news/fa/news/8190069/سرمربی-سپاهان-روی-نیمکت-تیم-ملی-عراق', 'https://www.yjc.news/fa/news/8190523/صفا-هادی-به-تراکتور-پیوست', 'https://www.yjc.news/fa/news/8187124/سعیدی-فر-در-استقلال-ماندنی-شد', 'https://www.yjc.news/fa/news/8176252/قرارداد-سید-جلال-حسینی-و-محمد-عسگری-با-پرسپولیس-امضا-شد', 'https://www.yjc.news/fa/news/8190883/رضاوند-در-۲-راهی-فولاد-و-استقلال-نه-قاطع-ساپینتو-به-آرش', 'https://www.yjc.news/fa/news/8173113/مهدی-پور-با-استقلال-تمدید-کرد-حامدی-فر-قرارداد-بست', 'https://www.yjc.news/fa/news/8170286/صادقی-پرسپولیسی-شد', 'https://www.yjc.news/fa/news/8166243/پیشنهاد-رسانه-انگلیسی-به-منچستر-یونایتد-برای-جذب-طارمی-زوج-طارمی-رونالدو-به-حقیقت-می\\u200cپیوندد', 'https://www.yjc.news/fa/news/8186968/رضاییان-راهی-سپاهان-شد']\n","['ابراهیمی از پرسپولیس جدا شد', 'سرمربی سپاهان روی نیمکت تیم ملی عراق', 'صفا هادی به تراکتور پیوست', 'سعیدی فر در استقلال ماندنی شد', 'قرارداد سید جلال حسینی و محمد عسگری با پرسپولیس امضا شد', 'رضاوند در 2 راهی فولاد و استقلال / نه قاطع ساپینتو به ارش', 'مهدی پور با استقلال تمدید کرد / حامدی فر قرارداد بست', 'صادقی پرسپولیسی شد', 'پیشنهاد رسانه انگلیسی به منچستر یونایتد برای جذب طارمی / زوج طارمی - رونالدو به حقیقت می\\u200cپیوندد ؟', 'رضاییان راهی سپاهان شد']\n"]}]}]}